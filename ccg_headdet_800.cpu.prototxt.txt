name: "HEADDET_CCG_PANACAST800x200_deploy"
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 200
      dim: 800
    }
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "BatchNorm1"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNormA1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "BatchNormA1"
  top: "BatchNorm2"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNormA2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "BatchNormA2"
  top: "BatchNorm3"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA3"
  type: "ReLU"
  bottom: "BatchNorm3"
  top: "BatchNormA3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "BatchNormA3"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Pooling1"
  top: "BatchNorm4"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "BatchNorm4"
  top: "BatchNorm4"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "BatchNorm4"
  top: "BatchNorm4"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "BatchNorm4"
  top: "BatchNorm5"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA4"
  type: "ReLU"
  bottom: "BatchNorm5"
  top: "BatchNormA5"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "BatchNormA5"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Convolution5"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Concat1"
  top: "BatchNorm6"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "BatchNorm6"
  top: "BatchNorm6"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "BatchNorm6"
  top: "BatchNorm6"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "BatchNorm6"
  top: "BatchNorm7"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA5"
  type: "ReLU"
  bottom: "BatchNorm7"
  top: "BatchNormA7"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "BatchNormA7"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Concat1"
  bottom: "Convolution7"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Concat2"
  top: "BatchNorm8"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "BatchNorm8"
  top: "BatchNorm8"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "BatchNorm8"
  top: "BatchNorm8"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "BatchNorm8"
  top: "BatchNorm9"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA6"
  type: "ReLU"
  bottom: "BatchNorm9"
  top: "BatchNormA9"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "BatchNormA9"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "Concat2"
  bottom: "Convolution9"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Concat3"
  top: "BatchNorm10"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "BatchNorm10"
  top: "BatchNorm10"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "BatchNorm10"
  top: "BatchNorm10"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "BatchNorm10"
  top: "BatchNorm11"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA7"
  type: "ReLU"
  bottom: "BatchNorm11"
  top: "BatchNormA11"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "BatchNormA11"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "Concat3"
  bottom: "Convolution11"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Concat4"
  top: "BatchNorm12"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "BatchNorm12"
  top: "BatchNorm12"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "BatchNorm12"
  top: "BatchNorm12"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "BatchNorm12"
  top: "BatchNorm13"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA8"
  type: "ReLU"
  bottom: "BatchNorm13"
  top: "BatchNormA13"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "BatchNormA13"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "Concat4"
  bottom: "Convolution13"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Concat5"
  top: "BatchNorm14"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "BatchNorm14"
  top: "BatchNorm14"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "BatchNorm14"
  top: "BatchNorm14"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "BatchNorm14"
  top: "BatchNorm15"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA9"
  type: "ReLU"
  bottom: "BatchNorm15"
  top: "BatchNormA15"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "BatchNormA15"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "Concat5"
  bottom: "Convolution15"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Concat6"
  top: "BatchNorm16"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "BatchNorm16"
  top: "BatchNorm16"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "BatchNorm16"
  top: "ReLU16"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "ReLU16"
  top: "Convolution16"
  convolution_param {
    num_output: 224
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Convolution16"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Pooling2"
  top: "BatchNorm17"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "BatchNorm17"
  top: "BatchNorm17"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "BatchNorm17"
  top: "BatchNorm17"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "BatchNorm17"
  top: "BatchNorm18"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA10"
  type: "ReLU"
  bottom: "BatchNorm18"
  top: "BatchNormA18"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "BatchNormA18"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "Pooling2"
  bottom: "Convolution18"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Concat7"
  top: "BatchNorm19"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "BatchNorm19"
  top: "BatchNorm19"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "BatchNorm19"
  top: "BatchNorm19"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "BatchNorm19"
  top: "BatchNorm20"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA11"
  type: "ReLU"
  bottom: "BatchNorm20"
  top: "BatchNormA20"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "BatchNormA20"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "Concat7"
  bottom: "Convolution20"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Concat8"
  top: "BatchNorm21"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "BatchNorm21"
  top: "BatchNorm21"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "BatchNorm21"
  top: "BatchNorm21"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "BatchNorm21"
  top: "BatchNorm22"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA12"
  type: "ReLU"
  bottom: "BatchNorm22"
  top: "BatchNormA22"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "BatchNormA22"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "Concat8"
  bottom: "Convolution22"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Concat9"
  top: "BatchNorm23"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "BatchNorm23"
  top: "BatchNorm23"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "BatchNorm23"
  top: "BatchNorm23"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "BatchNorm23"
  top: "BatchNorm24"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA13"
  type: "ReLU"
  bottom: "BatchNorm24"
  top: "BatchNormA24"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "BatchNormA24"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "Concat9"
  bottom: "Convolution24"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Concat10"
  top: "BatchNorm25"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "BatchNorm25"
  top: "BatchNorm25"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "BatchNorm25"
  top: "BatchNorm25"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "BatchNorm25"
  top: "BatchNorm26"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA14"
  type: "ReLU"
  bottom: "BatchNorm26"
  top: "BatchNormA26"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "BatchNormA26"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "Concat10"
  bottom: "Convolution26"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Concat11"
  top: "BatchNorm27"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "BatchNorm27"
  top: "BatchNorm27"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "BatchNorm27"
  top: "BatchNorm27"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "BatchNorm27"
  top: "BatchNorm28"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA15"
  type: "ReLU"
  bottom: "BatchNorm28"
  top: "BatchNormA28"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "BatchNormA28"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "Concat11"
  bottom: "Convolution28"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Concat12"
  top: "BatchNorm29"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "BatchNorm29"
  top: "BatchNorm29"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "BatchNorm29"
  top: "BatchNorm29"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "BatchNorm29"
  top: "BatchNorm30"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA16"
  type: "ReLU"
  bottom: "BatchNorm30"
  top: "BatchNormA30"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "BatchNormA30"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "Concat12"
  bottom: "Convolution30"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Concat13"
  top: "BatchNorm31"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "BatchNorm31"
  top: "BatchNorm31"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "BatchNorm31"
  top: "BatchNorm31"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "BatchNorm31"
  top: "BatchNorm32"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA17"
  type: "ReLU"
  bottom: "BatchNorm32"
  top: "BatchNormA32"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "BatchNormA32"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "Concat13"
  bottom: "Convolution32"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Concat14"
  top: "BatchNorm33"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "BatchNorm33"
  top: "BatchNorm33"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "BatchNorm33"
  top: "ReLU33"
}
layer {
  name: "First"
  type: "Convolution"
  bottom: "ReLU33"
  top: "First"
  convolution_param {
    num_output: 352
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "First"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Pooling3"
  top: "BatchNorm34"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "BatchNorm34"
  top: "BatchNorm34"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "BatchNorm34"
  top: "BatchNorm34"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "BatchNorm34"
  top: "BatchNorm35"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA18"
  type: "ReLU"
  bottom: "BatchNorm35"
  top: "BatchNormA35"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "BatchNormA35"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "Pooling3"
  bottom: "Convolution34"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm36"
  type: "BatchNorm"
  bottom: "Concat15"
  top: "BatchNorm36"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale36"
  type: "Scale"
  bottom: "BatchNorm36"
  top: "BatchNorm36"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "BatchNorm36"
  top: "BatchNorm36"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "BatchNorm36"
  top: "BatchNorm37"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA19"
  type: "ReLU"
  bottom: "BatchNorm37"
  top: "BatchNormA37"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "BatchNormA37"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "Concat15"
  bottom: "Convolution36"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm38"
  type: "BatchNorm"
  bottom: "Concat16"
  top: "BatchNorm38"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale38"
  type: "Scale"
  bottom: "BatchNorm38"
  top: "BatchNorm38"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU38"
  type: "ReLU"
  bottom: "BatchNorm38"
  top: "BatchNorm38"
}
layer {
  name: "Convolution37"
  type: "Convolution"
  bottom: "BatchNorm38"
  top: "BatchNorm39"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA20"
  type: "ReLU"
  bottom: "BatchNorm39"
  top: "BatchNormA39"
}
layer {
  name: "Convolution38"
  type: "Convolution"
  bottom: "BatchNormA39"
  top: "Convolution38"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "Concat16"
  bottom: "Convolution38"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm40"
  type: "BatchNorm"
  bottom: "Concat17"
  top: "BatchNorm40"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale40"
  type: "Scale"
  bottom: "BatchNorm40"
  top: "BatchNorm40"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU40"
  type: "ReLU"
  bottom: "BatchNorm40"
  top: "BatchNorm40"
}
layer {
  name: "Convolution39"
  type: "Convolution"
  bottom: "BatchNorm40"
  top: "BatchNorm41"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA21"
  type: "ReLU"
  bottom: "BatchNorm41"
  top: "BatchNormA41"
}
layer {
  name: "Convolution40"
  type: "Convolution"
  bottom: "BatchNormA41"
  top: "Convolution40"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "Concat17"
  bottom: "Convolution40"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm42"
  type: "BatchNorm"
  bottom: "Concat18"
  top: "BatchNorm42"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale42"
  type: "Scale"
  bottom: "BatchNorm42"
  top: "BatchNorm42"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU42"
  type: "ReLU"
  bottom: "BatchNorm42"
  top: "BatchNorm42"
}
layer {
  name: "Convolution41"
  type: "Convolution"
  bottom: "BatchNorm42"
  top: "BatchNorm43"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA22"
  type: "ReLU"
  bottom: "BatchNorm43"
  top: "BatchNormA43"
}
layer {
  name: "Convolution42"
  type: "Convolution"
  bottom: "BatchNormA43"
  top: "Convolution42"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "Concat18"
  bottom: "Convolution42"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm44"
  type: "BatchNorm"
  bottom: "Concat19"
  top: "BatchNorm44"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale44"
  type: "Scale"
  bottom: "BatchNorm44"
  top: "BatchNorm44"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU44"
  type: "ReLU"
  bottom: "BatchNorm44"
  top: "BatchNorm44"
}
layer {
  name: "Convolution43"
  type: "Convolution"
  bottom: "BatchNorm44"
  top: "BatchNorm45"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA23"
  type: "ReLU"
  bottom: "BatchNorm45"
  top: "BatchNormA45"
}
layer {
  name: "Convolution44"
  type: "Convolution"
  bottom: "BatchNormA45"
  top: "Convolution44"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat20"
  type: "Concat"
  bottom: "Concat19"
  bottom: "Convolution44"
  top: "Concat20"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm46"
  type: "BatchNorm"
  bottom: "Concat20"
  top: "BatchNorm46"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale46"
  type: "Scale"
  bottom: "BatchNorm46"
  top: "BatchNorm46"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU46"
  type: "ReLU"
  bottom: "BatchNorm46"
  top: "BatchNorm46"
}
layer {
  name: "Convolution45"
  type: "Convolution"
  bottom: "BatchNorm46"
  top: "BatchNorm47"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA24"
  type: "ReLU"
  bottom: "BatchNorm47"
  top: "BatchNormA47"
}
layer {
  name: "Convolution46"
  type: "Convolution"
  bottom: "BatchNormA47"
  top: "Convolution46"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat21"
  type: "Concat"
  bottom: "Concat20"
  bottom: "Convolution46"
  top: "Concat21"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm48"
  type: "BatchNorm"
  bottom: "Concat21"
  top: "BatchNorm48"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale48"
  type: "Scale"
  bottom: "BatchNorm48"
  top: "BatchNorm48"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU48"
  type: "ReLU"
  bottom: "BatchNorm48"
  top: "BatchNorm48"
}
layer {
  name: "Convolution47"
  type: "Convolution"
  bottom: "BatchNorm48"
  top: "BatchNorm49"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA25"
  type: "ReLU"
  bottom: "BatchNorm49"
  top: "BatchNormA49"
}
layer {
  name: "Convolution48"
  type: "Convolution"
  bottom: "BatchNormA49"
  top: "Convolution48"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat22"
  type: "Concat"
  bottom: "Concat21"
  bottom: "Convolution48"
  top: "Concat22"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm50"
  type: "BatchNorm"
  bottom: "Concat22"
  top: "BatchNorm50"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale50"
  type: "Scale"
  bottom: "BatchNorm50"
  top: "BatchNorm50"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU50"
  type: "ReLU"
  bottom: "BatchNorm50"
  top: "ReLU50"
}
layer {
  name: "Convolution49"
  type: "Convolution"
  bottom: "ReLU50"
  top: "Convolution49"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm51"
  type: "BatchNorm"
  bottom: "Convolution49"
  top: "BatchNorm51"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale51"
  type: "Scale"
  bottom: "BatchNorm51"
  top: "BatchNorm51"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU51"
  type: "ReLU"
  bottom: "BatchNorm51"
  top: "BatchNorm51"
}
layer {
  name: "Convolution50"
  type: "Convolution"
  bottom: "BatchNorm51"
  top: "BatchNorm52"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA26"
  type: "ReLU"
  bottom: "BatchNorm52"
  top: "BatchNormA52"
}
layer {
  name: "Convolution51"
  type: "Convolution"
  bottom: "BatchNormA52"
  top: "Convolution51"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat23"
  type: "Concat"
  bottom: "Convolution49"
  bottom: "Convolution51"
  top: "Concat23"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm53"
  type: "BatchNorm"
  bottom: "Concat23"
  top: "BatchNorm53"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale53"
  type: "Scale"
  bottom: "BatchNorm53"
  top: "BatchNorm53"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU53"
  type: "ReLU"
  bottom: "BatchNorm53"
  top: "BatchNorm53"
}
layer {
  name: "Convolution52"
  type: "Convolution"
  bottom: "BatchNorm53"
  top: "BatchNorm54"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA27"
  type: "ReLU"
  bottom: "BatchNorm54"
  top: "BatchNormA54"
}
layer {
  name: "Convolution53"
  type: "Convolution"
  bottom: "BatchNormA54"
  top: "Convolution53"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat24"
  type: "Concat"
  bottom: "Concat23"
  bottom: "Convolution53"
  top: "Concat24"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm55"
  type: "BatchNorm"
  bottom: "Concat24"
  top: "BatchNorm55"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale55"
  type: "Scale"
  bottom: "BatchNorm55"
  top: "BatchNorm55"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU55"
  type: "ReLU"
  bottom: "BatchNorm55"
  top: "BatchNorm55"
}
layer {
  name: "Convolution54"
  type: "Convolution"
  bottom: "BatchNorm55"
  top: "BatchNorm56"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA28"
  type: "ReLU"
  bottom: "BatchNorm56"
  top: "BatchNormA56"
}
layer {
  name: "Convolution55"
  type: "Convolution"
  bottom: "BatchNormA56"
  top: "Convolution55"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat25"
  type: "Concat"
  bottom: "Concat24"
  bottom: "Convolution55"
  top: "Concat25"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm57"
  type: "BatchNorm"
  bottom: "Concat25"
  top: "BatchNorm57"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale57"
  type: "Scale"
  bottom: "BatchNorm57"
  top: "BatchNorm57"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU57"
  type: "ReLU"
  bottom: "BatchNorm57"
  top: "BatchNorm57"
}
layer {
  name: "Convolution56"
  type: "Convolution"
  bottom: "BatchNorm57"
  top: "BatchNorm58"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA29"
  type: "ReLU"
  bottom: "BatchNorm58"
  top: "BatchNormA58"
}
layer {
  name: "Convolution57"
  type: "Convolution"
  bottom: "BatchNormA58"
  top: "Convolution57"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat26"
  type: "Concat"
  bottom: "Concat25"
  bottom: "Convolution57"
  top: "Concat26"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm59"
  type: "BatchNorm"
  bottom: "Concat26"
  top: "BatchNorm59"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale59"
  type: "Scale"
  bottom: "BatchNorm59"
  top: "BatchNorm59"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU59"
  type: "ReLU"
  bottom: "BatchNorm59"
  top: "BatchNorm59"
}
layer {
  name: "Convolution58"
  type: "Convolution"
  bottom: "BatchNorm59"
  top: "BatchNorm60"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA30"
  type: "ReLU"
  bottom: "BatchNorm60"
  top: "BatchNormA60"
}
layer {
  name: "Convolution59"
  type: "Convolution"
  bottom: "BatchNormA60"
  top: "Convolution59"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat27"
  type: "Concat"
  bottom: "Concat26"
  bottom: "Convolution59"
  top: "Concat27"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm61"
  type: "BatchNorm"
  bottom: "Concat27"
  top: "BatchNorm61"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale61"
  type: "Scale"
  bottom: "BatchNorm61"
  top: "BatchNorm61"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU61"
  type: "ReLU"
  bottom: "BatchNorm61"
  top: "BatchNorm61"
}
layer {
  name: "Convolution60"
  type: "Convolution"
  bottom: "BatchNorm61"
  top: "BatchNorm62"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA31"
  type: "ReLU"
  bottom: "BatchNorm62"
  top: "BatchNormA62"
}
layer {
  name: "Convolution61"
  type: "Convolution"
  bottom: "BatchNormA62"
  top: "Convolution61"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat28"
  type: "Concat"
  bottom: "Concat27"
  bottom: "Convolution61"
  top: "Concat28"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm63"
  type: "BatchNorm"
  bottom: "Concat28"
  top: "BatchNorm63"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale63"
  type: "Scale"
  bottom: "BatchNorm63"
  top: "BatchNorm63"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU63"
  type: "ReLU"
  bottom: "BatchNorm63"
  top: "BatchNorm63"
}
layer {
  name: "Convolution62"
  type: "Convolution"
  bottom: "BatchNorm63"
  top: "BatchNorm64"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA32"
  type: "ReLU"
  bottom: "BatchNorm64"
  top: "BatchNormA64"
}
layer {
  name: "Convolution63"
  type: "Convolution"
  bottom: "BatchNormA64"
  top: "Convolution63"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat29"
  type: "Concat"
  bottom: "Concat28"
  bottom: "Convolution63"
  top: "Concat29"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm65"
  type: "BatchNorm"
  bottom: "Concat29"
  top: "BatchNorm65"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale65"
  type: "Scale"
  bottom: "BatchNorm65"
  top: "BatchNorm65"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU65"
  type: "ReLU"
  bottom: "BatchNorm65"
  top: "BatchNorm65"
}
layer {
  name: "Convolution64"
  type: "Convolution"
  bottom: "BatchNorm65"
  top: "BatchNorm66"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA33"
  type: "ReLU"
  bottom: "BatchNorm66"
  top: "BatchNormA66"
}
layer {
  name: "Convolution65"
  type: "Convolution"
  bottom: "BatchNormA66"
  top: "Convolution65"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Concat30"
  type: "Concat"
  bottom: "Concat29"
  bottom: "Convolution65"
  top: "Concat30"
  concat_param {
    axis: 1
  }
}
layer {
  name: "BatchNorm67"
  type: "BatchNorm"
  bottom: "Concat30"
  top: "BatchNorm67"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale67"
  type: "Scale"
  bottom: "BatchNorm67"
  top: "BatchNorm67"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU67"
  type: "ReLU"
  bottom: "BatchNorm67"
  top: "ReLU67"
}
layer {
  name: "Convolution66"
  type: "Convolution"
  bottom: "ReLU67"
  top: "Convolution66"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "First"
  top: "Pooling4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm68"
  type: "BatchNorm"
  bottom: "Pooling4"
  top: "BatchNorm68"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale68"
  type: "Scale"
  bottom: "BatchNorm68"
  top: "BatchNorm68"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU68"
  type: "ReLU"
  bottom: "BatchNorm68"
  top: "BatchNorm68"
}
layer {
  name: "Convolution67"
  type: "Convolution"
  bottom: "BatchNorm68"
  top: "Convolution67"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Second"
  type: "Concat"
  bottom: "Convolution66"
  bottom: "Convolution67"
  top: "Second"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Second"
  top: "Pooling5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm69"
  type: "BatchNorm"
  bottom: "Pooling5"
  top: "BatchNorm69"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale69"
  type: "Scale"
  bottom: "BatchNorm69"
  top: "BatchNorm69"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU69"
  type: "ReLU"
  bottom: "BatchNorm69"
  top: "BatchNorm69"
}
layer {
  name: "Convolution68"
  type: "Convolution"
  bottom: "BatchNorm69"
  top: "Convolution68"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm70"
  type: "BatchNorm"
  bottom: "Second"
  top: "BatchNorm70"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale70"
  type: "Scale"
  bottom: "BatchNorm70"
  top: "BatchNorm70"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU70"
  type: "ReLU"
  bottom: "BatchNorm70"
  top: "BatchNorm70"
}
layer {
  name: "Convolution69"
  type: "Convolution"
  bottom: "BatchNorm70"
  top: "BatchNorm71"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA34"
  type: "ReLU"
  bottom: "BatchNorm71"
  top: "BatchNormA71"
}
layer {
  name: "Convolution70"
  type: "Convolution"
  bottom: "BatchNormA71"
  top: "Convolution70"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Third"
  type: "Concat"
  bottom: "Convolution68"
  bottom: "Convolution70"
  top: "Third"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling6"
  type: "Pooling"
  bottom: "Third"
  top: "Pooling6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm72"
  type: "BatchNorm"
  bottom: "Pooling6"
  top: "BatchNorm72"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale72"
  type: "Scale"
  bottom: "BatchNorm72"
  top: "BatchNorm72"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU72"
  type: "ReLU"
  bottom: "BatchNorm72"
  top: "BatchNorm72"
}
layer {
  name: "Convolution71"
  type: "Convolution"
  bottom: "BatchNorm72"
  top: "Convolution71"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm73"
  type: "BatchNorm"
  bottom: "Third"
  top: "BatchNorm73"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale73"
  type: "Scale"
  bottom: "BatchNorm73"
  top: "BatchNorm73"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU73"
  type: "ReLU"
  bottom: "BatchNorm73"
  top: "BatchNorm73"
}
layer {
  name: "Convolution72"
  type: "Convolution"
  bottom: "BatchNorm73"
  top: "BatchNorm74"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA35"
  type: "ReLU"
  bottom: "BatchNorm74"
  top: "BatchNormA74"
}
layer {
  name: "Convolution73"
  type: "Convolution"
  bottom: "BatchNormA74"
  top: "Convolution73"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Fourth"
  type: "Concat"
  bottom: "Convolution71"
  bottom: "Convolution73"
  top: "Fourth"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling7"
  type: "Pooling"
  bottom: "Fourth"
  top: "Pooling7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm75"
  type: "BatchNorm"
  bottom: "Pooling7"
  top: "BatchNorm75"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale75"
  type: "Scale"
  bottom: "BatchNorm75"
  top: "BatchNorm75"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU75"
  type: "ReLU"
  bottom: "BatchNorm75"
  top: "BatchNorm75"
}
layer {
  name: "Convolution74"
  type: "Convolution"
  bottom: "BatchNorm75"
  top: "Convolution74"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm76"
  type: "BatchNorm"
  bottom: "Fourth"
  top: "BatchNorm76"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale76"
  type: "Scale"
  bottom: "BatchNorm76"
  top: "BatchNorm76"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU76"
  type: "ReLU"
  bottom: "BatchNorm76"
  top: "BatchNorm76"
}
layer {
  name: "Convolution75"
  type: "Convolution"
  bottom: "BatchNorm76"
  top: "BatchNorm77"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA36"
  type: "ReLU"
  bottom: "BatchNorm77"
  top: "BatchNormA77"
}
layer {
  name: "Convolution76"
  type: "Convolution"
  bottom: "BatchNormA77"
  top: "Convolution76"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Fifth"
  type: "Concat"
  bottom: "Convolution74"
  bottom: "Convolution76"
  top: "Fifth"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling8"
  type: "Pooling"
  bottom: "Fifth"
  top: "Pooling8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "BatchNorm78"
  type: "BatchNorm"
  bottom: "Pooling8"
  top: "BatchNorm78"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale78"
  type: "Scale"
  bottom: "BatchNorm78"
  top: "BatchNorm78"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU78"
  type: "ReLU"
  bottom: "BatchNorm78"
  top: "BatchNorm78"
}
layer {
  name: "Convolution77"
  type: "Convolution"
  bottom: "BatchNorm78"
  top: "Convolution77"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm79"
  type: "BatchNorm"
  bottom: "Fifth"
  top: "BatchNorm79"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale79"
  type: "Scale"
  bottom: "BatchNorm79"
  top: "BatchNorm79"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU79"
  type: "ReLU"
  bottom: "BatchNorm79"
  top: "BatchNorm79"
}
layer {
  name: "Convolution78"
  type: "Convolution"
  bottom: "BatchNorm79"
  top: "BatchNorm80"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ReLUA37"
  type: "ReLU"
  bottom: "BatchNorm80"
  top: "BatchNormA80"
}
layer {
  name: "Convolution79"
  type: "Convolution"
  bottom: "BatchNormA80"
  top: "Convolution79"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Sixth"
  type: "Concat"
  bottom: "Convolution77"
  bottom: "Convolution79"
  top: "Sixth"
  concat_param {
    axis: 1
  }
}
layer {
  name: "First_norm"
  type: "Normalize"
  bottom: "First"
  top: "First_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "First_norm_mbox_loc"
  type: "Convolution"
  bottom: "First_norm"
  top: "First_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "First_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "First_norm_mbox_loc"
  top: "First_norm_mbox_loc"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "First_norm_mbox_loc_scale"
  type: "Scale"
  bottom: "First_norm_mbox_loc"
  top: "First_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "First_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "First_norm_mbox_loc"
  top: "First_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "First_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "First_norm_mbox_loc_perm"
  top: "First_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "First_norm_mbox_conf"
  type: "Convolution"
  bottom: "First_norm"
  top: "First_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "First_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "First_norm_mbox_conf"
  top: "First_norm_mbox_conf"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "First_norm_mbox_conf_scale"
  type: "Scale"
  bottom: "First_norm_mbox_conf"
  top: "First_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "First_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "First_norm_mbox_conf"
  top: "First_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "First_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "First_norm_mbox_conf_perm"
  top: "First_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "First_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "First_norm"
  bottom: "data"
  top: "First_norm_mbox_priorbox"
  prior_box_param {
    min_size: 10.0
    max_size: 40.0
    aspect_ratio: 2.0
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "Second_norm"
  type: "Normalize"
  bottom: "Second"
  top: "Second_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Second_norm_mbox_loc"
  type: "Convolution"
  bottom: "Second_norm"
  top: "Second_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Second_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Second_norm_mbox_loc"
  top: "Second_norm_mbox_loc"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Second_norm_mbox_loc_scale"
  type: "Scale"
  bottom: "Second_norm_mbox_loc"
  top: "Second_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Second_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "Second_norm_mbox_loc"
  top: "Second_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Second_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "Second_norm_mbox_loc_perm"
  top: "Second_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Second_norm_mbox_conf"
  type: "Convolution"
  bottom: "Second_norm"
  top: "Second_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 18
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Second_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Second_norm_mbox_conf"
  top: "Second_norm_mbox_conf"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Second_norm_mbox_conf_scale"
  type: "Scale"
  bottom: "Second_norm_mbox_conf"
  top: "Second_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Second_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "Second_norm_mbox_conf"
  top: "Second_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Second_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "Second_norm_mbox_conf_perm"
  top: "Second_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Second_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Second_norm"
  bottom: "data"
  top: "Second_norm_mbox_priorbox"
  prior_box_param {
    min_size: 40.0
    max_size: 70.0
    aspect_ratio: 2.0
    aspect_ratio: 3.0
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "Third_norm"
  type: "Normalize"
  bottom: "Third"
  top: "Third_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Third_norm_mbox_loc"
  type: "Convolution"
  bottom: "Third_norm"
  top: "Third_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Third_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Third_norm_mbox_loc"
  top: "Third_norm_mbox_loc"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Third_norm_mbox_loc_scale"
  type: "Scale"
  bottom: "Third_norm_mbox_loc"
  top: "Third_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Third_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "Third_norm_mbox_loc"
  top: "Third_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Third_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "Third_norm_mbox_loc_perm"
  top: "Third_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Third_norm_mbox_conf"
  type: "Convolution"
  bottom: "Third_norm"
  top: "Third_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 18
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Third_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Third_norm_mbox_conf"
  top: "Third_norm_mbox_conf"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Third_norm_mbox_conf_scale"
  type: "Scale"
  bottom: "Third_norm_mbox_conf"
  top: "Third_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Third_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "Third_norm_mbox_conf"
  top: "Third_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Third_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "Third_norm_mbox_conf_perm"
  top: "Third_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Third_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Third_norm"
  bottom: "data"
  top: "Third_norm_mbox_priorbox"
  prior_box_param {
    min_size: 70.0
    max_size: 100.0
    aspect_ratio: 2.0
    aspect_ratio: 3.0
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "Fourth_norm"
  type: "Normalize"
  bottom: "Fourth"
  top: "Fourth_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Fourth_norm_mbox_loc"
  type: "Convolution"
  bottom: "Fourth_norm"
  top: "Fourth_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Fourth_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Fourth_norm_mbox_loc"
  top: "Fourth_norm_mbox_loc"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Fourth_norm_mbox_loc_scale"
  type: "Scale"
  bottom: "Fourth_norm_mbox_loc"
  top: "Fourth_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fourth_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "Fourth_norm_mbox_loc"
  top: "Fourth_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fourth_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "Fourth_norm_mbox_loc_perm"
  top: "Fourth_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fourth_norm_mbox_conf"
  type: "Convolution"
  bottom: "Fourth_norm"
  top: "Fourth_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 18
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Fourth_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Fourth_norm_mbox_conf"
  top: "Fourth_norm_mbox_conf"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Fourth_norm_mbox_conf_scale"
  type: "Scale"
  bottom: "Fourth_norm_mbox_conf"
  top: "Fourth_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fourth_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "Fourth_norm_mbox_conf"
  top: "Fourth_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fourth_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "Fourth_norm_mbox_conf_perm"
  top: "Fourth_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fourth_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Fourth_norm"
  bottom: "data"
  top: "Fourth_norm_mbox_priorbox"
  prior_box_param {
    min_size: 100.0
    max_size: 130.0
    aspect_ratio: 2.0
    aspect_ratio: 3.0
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "Fifth_norm"
  type: "Normalize"
  bottom: "Fifth"
  top: "Fifth_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Fifth_norm_mbox_loc"
  type: "Convolution"
  bottom: "Fifth_norm"
  top: "Fifth_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Fifth_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Fifth_norm_mbox_loc"
  top: "Fifth_norm_mbox_loc"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Fifth_norm_mbox_loc_scale"
  type: "Scale"
  bottom: "Fifth_norm_mbox_loc"
  top: "Fifth_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fifth_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "Fifth_norm_mbox_loc"
  top: "Fifth_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fifth_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "Fifth_norm_mbox_loc_perm"
  top: "Fifth_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fifth_norm_mbox_conf"
  type: "Convolution"
  bottom: "Fifth_norm"
  top: "Fifth_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Fifth_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Fifth_norm_mbox_conf"
  top: "Fifth_norm_mbox_conf"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Fifth_norm_mbox_conf_scale"
  type: "Scale"
  bottom: "Fifth_norm_mbox_conf"
  top: "Fifth_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fifth_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "Fifth_norm_mbox_conf"
  top: "Fifth_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fifth_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "Fifth_norm_mbox_conf_perm"
  top: "Fifth_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fifth_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Fifth_norm"
  bottom: "data"
  top: "Fifth_norm_mbox_priorbox"
  prior_box_param {
    min_size: 130.0
    max_size: 160.0
    aspect_ratio: 2.0
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "Sixth_norm"
  type: "Normalize"
  bottom: "Sixth"
  top: "Sixth_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Sixth_norm_mbox_loc"
  type: "Convolution"
  bottom: "Sixth_norm"
  top: "Sixth_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Sixth_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Sixth_norm_mbox_loc"
  top: "Sixth_norm_mbox_loc"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Sixth_norm_mbox_loc_scale"
  type: "Scale"
  bottom: "Sixth_norm_mbox_loc"
  top: "Sixth_norm_mbox_loc"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Sixth_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "Sixth_norm_mbox_loc"
  top: "Sixth_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Sixth_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "Sixth_norm_mbox_loc_perm"
  top: "Sixth_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Sixth_norm_mbox_conf"
  type: "Convolution"
  bottom: "Sixth_norm"
  top: "Sixth_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "Sixth_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Sixth_norm_mbox_conf"
  top: "Sixth_norm_mbox_conf"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "Sixth_norm_mbox_conf_scale"
  type: "Scale"
  bottom: "Sixth_norm_mbox_conf"
  top: "Sixth_norm_mbox_conf"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Sixth_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "Sixth_norm_mbox_conf"
  top: "Sixth_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Sixth_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "Sixth_norm_mbox_conf_perm"
  top: "Sixth_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Sixth_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Sixth_norm"
  bottom: "data"
  top: "Sixth_norm_mbox_priorbox"
  prior_box_param {
    min_size: 160.0
    max_size: 200.0
    aspect_ratio: 2.0
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "First_norm_mbox_loc_flat"
  bottom: "Second_norm_mbox_loc_flat"
  bottom: "Third_norm_mbox_loc_flat"
  bottom: "Fourth_norm_mbox_loc_flat"
  bottom: "Fifth_norm_mbox_loc_flat"
  bottom: "Sixth_norm_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "First_norm_mbox_conf_flat"
  bottom: "Second_norm_mbox_conf_flat"
  bottom: "Third_norm_mbox_conf_flat"
  bottom: "Fourth_norm_mbox_conf_flat"
  bottom: "Fifth_norm_mbox_conf_flat"
  bottom: "Sixth_norm_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "First_norm_mbox_priorbox"
  bottom: "Second_norm_mbox_priorbox"
  bottom: "Third_norm_mbox_priorbox"
  bottom: "Fourth_norm_mbox_priorbox"
  bottom: "Fifth_norm_mbox_priorbox"
  bottom: "Sixth_norm_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 3
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 3
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
